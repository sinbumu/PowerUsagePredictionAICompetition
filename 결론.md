# 결론 및 회고

## 개요
- 대회: 2025 전력사용량 예측 AI 경진대회 (SMAPE, 낮을수록 우수)
- 목표: 100개 건물 2024-08-25 ~ 08-31 전력사용량 예측
- 최종 상태: 파이프라인 구축, 베이스라인→CatBoost 중심 개선, 제출/기록 자동화 완료

## 진행 요약
- 데이터/전처리
  - 한글 컬럼 매핑, `timestamp` 파싱 일관화
  - 누수 방지: `shift(1)→rolling`, `lag168` 기준 잔차 프레임
  - `test.csv`에 일조/일사(now) 부재 대응: 과거 기반(lag/rolling) 유지, imputer로 `now_hat` 생성/활용
- 피처
  - 시간: `hour_of_week`, 주기(sin/cos), `cdd/hdd`, `dew_point`, `heat_index`
  - 부하: `lag_1/24/168/336`, `roll_mean_24/168/336`
  - 기상: now(`temp/rain/wind/humid`)의 `lag168/diff168`, 과거(`sunshine/irradiance`) 파생
  - 메타: `pv_capacity × irradiance_lag168` 등, 그리고 (선택) `pv × irradiance_now_hat`
- 검증
  - 앵커드 3주 블록 CV(각 7일, gap 24h)를 표준으로 사용
  - 내부 지표는 SMAPE 통일, Cat/XGB에서 OOF 로그/메타 저장
- 모델/제출
  - 베이스라인(lag168+rolling blend)
  - 잔차 모델: Linear, GBM(HGB/LGBM 폴백), CatBoost, XGBoost
  - 앙상블: 가중(그리드) 및 단순 평균, 제출/품질체크 스크립트

## 성과(리더보드 기준)
- Public 최저 점수: `sub_cat_tune_d10_lr003_l2_6.csv` → 9.3669
- 이후 변형(시간감쇠, 바이어스 보정, 과도한 튠, XGB, 타입별 앙상블)은 개선 폭 제한 또는 악화
- 결론적으로 CatBoost(anchored CV + SMAPE 가중 + now_hat, time-decay=0)가 가장 안정적

## 시도/결과 하이라이트
- 효과적이었음
  - CatBoost 잔차 프레임 + 앵커드 3주 CV
  - SMAPE 근사 가중(`1/(|y|+c)`), c=150~200 근방
  - `now_hat(일조/일사)` + (보수적) `pv×irradiance_now_hat` 상호작용
- 제한적/역효과
  - 시간 감쇠 가중(time-decay): Public에서 이득 불명확 또는 악화
  - 바이어스 보정(building×hour-of-week): OOF 향상 대비 Public 악화 사례 발생
  - XGBoost/GBM: OOF는 양호하나 Public 일반화 약함(점수 상승)
  - 타입별 전용 모델: 일부 타입 이득이나 전체 앙상블은 순효과 제한적

## 제출/실험 관리
- `SCORE.md`에 제출 파일 23개 기록(생성시각/점수/노트)
- `scripts/run_train.sh`, `scripts/run_infer.sh`, `scripts/check_quality.py`로 재현 및 품질 체크 자동화
- 파생 제출물: 베이스라인/단일(Cat/XGB)/앙상블/튜닝/now_hat/무가중 등 다양

## 한계 및 원인 가설
- `test` 주간 분포·패턴이 `train`과 상이: 시간 감쇠/바이어스와 같은 강한 사전형 가공이 Public에선 과적합 가능
- 일조/일사 now 부재로 태양광 영향 추정 한계 → now_hat로 일부 보정했으나 완전 대체는 어려움
- 타입별 데이터 수 불균형 및 일부 타입의 변동성↑ → 글로벌 단일 모델이 상대적으로 안정적

## 향후 권장(후속 작업 시)
- 안전한 범위의 CatBoost 근방 튠만 소폭 반복(depth=10, lr 0.028~0.032, l2 5~7, c=120~180)
- now_hat 품질 개선(피처 확장/모델 업그레이드) 및 `pv×irradiance_now_hat` 유지
- 세그먼트 가중은 아주 보수적으로 A/B(야간·주말 등), 효과 없으면 즉시 롤백
- 앙상블은 Cat 단일 기반 + 소량의 보수적 블렌딩(과도한 모델 혼합 지양)

## 재현 절차
- 환경
  ```bash
  python3 -m venv .venv && source .venv/bin/activate
  pip install -r requirements.txt
  ```
- 학습
  ```bash
  bash scripts/run_train.sh --model both --train data/train.csv --info data/building_info.csv --save_dir outputs/models
  # Cat/XGB 등 개별 학습은 README 실행 가이드 참조
  ```
- 추론/제출 생성
  ```bash
  bash scripts/run_infer.sh --mode ensemble \
    --train data/train.csv --test data/test.csv \
    --sample data/sample_submission.csv \
    --models_root outputs/models \
    --out outputs/submissions/sub_ens.csv
  ```
- 품질 체크
  ```bash
  python3 scripts/check_quality.py outputs/submissions/sub_ens.csv data/sample_submission.csv
  ```

## 마무리
- 본 저장소는 대회 규칙 준수/재현성/품질 체크에 초점을 두고 CatBoost 기반으로 안정적인 베이스라인을 구축했습니다.
- Public 기준 최고 성과는 CatBoost 튠B(depth=10, lr=0.03, l2=6)였으며, 강한 사전 가중(시간감쇠/바이어스)은 역효과 가능성이 확인되었습니다.
- 후속 기회가 있다면 Cat 근방의 보수적 탐색 + now_hat 고도화를 중심으로 추가 개선을 추천합니다.
